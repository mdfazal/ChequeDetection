{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --upgrade pip\n!pip install tf_slim\n!pip install pycocotools\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --user Cython -q\n!pip install --user contextlib2 -q\n!pip install --user pillow -q\n!pip install --user lxml -q\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U protobuf -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\ngit clone --depth 1 https://github.com/tensorflow/models\ncd /kaggle/working/models/research/\nprotoc object_detection/protos/*.proto --python_out=.\ncp object_detection/packages/tf2/setup.py .\npython -m pip install .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom PIL import Image\nimport io\nfrom object_detection.utils import dataset_util\nfrom google.protobuf import text_format\nfrom object_detection.protos import pipeline_pb2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# YOLO to TFRecord Format"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_tf_example(example):\n    filename = example['filename']\n    print(filename)\n    with tf.io.gfile.GFile(filename, 'rb') as fid:\n        encoded_jpg = io.BytesIO()\n        image = Image.open(filename)\n        image= image.resize((640,640))\n        image.save(encoded_jpg, format='JPEG')\n        encoded_jpg = encoded_jpg.getvalue()\n    width, height = image.size\n    # TODO(user): Populate the following variables from your example.\n    image_format = b'jpg'# or b'png'\n    \n    xmins = example['xmin'] # List of normalized left x coordinates in bounding box (1 per box)\n    xmaxs = example['xmax'] # List of normalized right x coordinates in bounding box\n             # (1 per box)\n    ymins = example['ymin'] # List of normalized top y coordinates in bounding box (1 per box)\n    ymaxs = example['ymax']# List of normalized bottom y coordinates in bounding box\n             # (1 per box)\n    classes_text = ['IssueBank','ReceiverName','AcNo','Amt','ChqNo','DateIss'] # List of string class name of bounding box (1 per box)\n    classes_text = [x.encode('utf-8') for x in classes_text]\n    classes = example['classid'].astype(np.int32) # List of integer class id of bounding box (1 per box)\n\n    tf_example = tf.train.Example(features=tf.train.Features(feature={\n      'image/height': dataset_util.int64_feature(height),\n      'image/width': dataset_util.int64_feature(width),\n      'image/filename': dataset_util.bytes_feature(filename.encode()),\n      'image/source_id': dataset_util.bytes_feature(filename.encode()),\n      'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n      'image/format': dataset_util.bytes_feature(image_format),\n      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n      'image/object/class/label': dataset_util.int64_list_feature(classes),\n    }))\n    return tf_example\n\ndef get_img_info(filename):\n    filename = filename.split('/')[-1]\n    with open('../input/chequedetection/Images/'+filename.replace('.jpg','.txt')) as f:\n        image_annotations = f.readlines()\n        f.close()\n    for i in range(len(image_annotations)):\n        image_annotations[i] = image_annotations[i].split(' ')\n    image_annotations = np.array(image_annotations).astype(np.float)\n    #image_annotations[:,1:] = np.array(image_annotations)[:,1:].astype(np.float)\n    image_annotations[:,0] = np.array(image_annotations)[:,0].astype(np.int)\n    return image_annotations\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"writer = tf.io.TFRecordWriter(\"./train.record\")\n\nwith open('../input/chequedetection/train.txt') as f:\n    files = f.readlines()\n    f.close()\n# TODO(user): Write code to read in your dataset to examples variable\n\nfor example in files:\n    example = example.replace(\"\\n\",\"\")\n    annotations = get_img_info(example)\n    ann_dict = {\"filename\":example,\"xmin\":annotations[:,1],\"ymin\":annotations[:,2],\n                \"xmax\":annotations[:,1]+annotations[:,3],\"ymax\":annotations[:,2]+annotations[:,4],\n                \"classid\":annotations[:,0]}\n    tf_example = create_tf_example(ann_dict)\n    writer.write(tf_example.SerializeToString())\n\nwriter.close()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"writer = tf.io.TFRecordWriter(\"./test.record\")\n\nwith open('../input/chequedetection/test.txt') as f:\n    files = f.readlines()\n    f.close()\n# TODO(user): Write code to read in your dataset to examples variable\ntrain = 0\nfor example in files:\n    example = example.replace(\"\\n\",\"\")\n    annotations = get_img_info(example)\n    ann_dict = {\"filename\":example,\"xmin\":annotations[:,1],\"ymin\":annotations[:,2],\n                \"xmax\":annotations[:,1]+annotations[:,3],\"ymax\":annotations[:,2]+annotations[:,4],\n                \"classid\":annotations[:,0]}\n    tf_example = create_tf_example(ann_dict)\n    writer.write(tf_example.SerializeToString())\n\nwriter.close()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SSD Mobilenet V1 from TF2 Detection Zoo"},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!tar -xf ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Customize Pipeline Config"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"                                                                                                                                                                                                                                       \npipeline_config = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \n\nwith tf.io.gfile.GFile('./ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/pipeline.config', \"r\") as f:                                                                                                                                                                                                                     \n    proto_str = f.read()                                                                                                                                                                                                                                          \n    text_format.Merge(proto_str, pipeline_config)                                                                                                                                                                                                                 \n\npipeline_config.model.ssd.num_classes = 6                                                                                                                                                                                          \npipeline_config.train_config.batch_size= 16\npipeline_config.train_config.fine_tune_checkpoint = \"/kaggle/working/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\npipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\npipeline_config.train_input_reader.label_map_path = \"../input/chequedetection/object-detection.pbtxt\"\npipeline_config.train_input_reader.tf_record_input_reader.input_path[:]  = [\"./train.record\"]\n\nconfig_text = text_format.MessageToString(pipeline_config) \n\nwith tf.io.gfile.GFile(\"./ed_pipeline.config\", \"wb\") as f:                                                                                                                                                                                                                \n    f.write(config_text)\n    f.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!sed -i 's/label_map_path: \\\"PATH_TO_BE_CONFIGURED\\\"/label_map_path: \\\"\\.\\.\\/input\\/chequedetection\\/object-detection.pbtxt\\\"/g' ./ed_pipeline.config\n!sed -i 's/PATH_TO_BE_CONFIGURED/\\.\\/test.record/g' ./ed_pipeline.config\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir cheque_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python3 ./models/research/object_detection/model_main_tf2.py \\\n--model_dir=/kaggle/working/cheque_model/\\\n--pipeline_config_path=./ed_pipeline.config\\\n--alsologtostderr \\\n--num_train_steps=1000 \\\n--sample_1_of_n_eval_examples=1 \\\n--num_eval_steps=50\\\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ./cheque_model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Export trained model"},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir saved_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python3 ./models/research/object_detection/exporter_main_v2.py \\\n  --pipeline_config_path=./ed_pipeline.config \\\n  --trained_checkpoint_dir=./cheque_model \\\n  --output_directory=./saved_model/ \\\n  --input_type=image_tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!zip -r model.zip /kaggle/working/saved_model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Clean up\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -r models","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}